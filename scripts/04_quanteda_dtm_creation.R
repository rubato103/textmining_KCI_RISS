# 05_quanteda_dtm_creation.R
# quantedaë¥¼ ì‚¬ìš©í•œ ë©”íƒ€ë°ì´í„° ë³´ì¡´ DTM ìƒì„±

# ========== íŒ¨í‚¤ì§€ ë¡œë“œ ==========
required_packages <- c("quanteda", "dplyr", "readr", "ggplot2", "wordcloud", "wordcloud2", "RColorBrewer", "htmlwidgets")

cat("í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸ ì¤‘...\n")
for (pkg in required_packages) {
  if (!require(pkg, character.only = TRUE)) {
    cat(paste("íŒ¨í‚¤ì§€", pkg, "ì„¤ì¹˜ ì¤‘...\n"))
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}
cat("âœ… ëª¨ë“  íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ\n")

# ========== í™˜ê²½ ì„¤ì • ==========
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
if (basename(getwd()) == "scripts") {
  setwd("..")
}

# ì‚¬ìš©ì ì…ë ¥ í•¨ìˆ˜ ë¡œë“œ
source("scripts/00_interactive_utils.R")

# ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
if (!dir.exists("plots")) dir.create("plots", recursive = TRUE)

# ========== ë°ì´í„° ë¡œë“œ ==========
cat("\n", rep("=", 60), "\n")
cat("ğŸ“Š quanteda DTM ìƒì„± (ë©”íƒ€ë°ì´í„° ë³´ì¡´)\n")
cat(rep("=", 60), "\n\n")

# 1. ëª…ì‚¬ ì¶”ì¶œ ê²°ê³¼ íŒŒì¼ ì„ íƒ
noun_extraction_files <- list.files("data/processed/", 
                                   pattern = "noun_extraction.*\\.csv$", 
                                   full.names = TRUE)

if (length(noun_extraction_files) == 0) {
  stop("noun_extraction íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 02_kiwipiepy_morpheme_analysis.Rì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
}

cat("ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ì‚¬ ì¶”ì¶œ íŒŒì¼:\n")
for (i in seq_along(noun_extraction_files)) {
  file_info <- file.info(noun_extraction_files[i])
  cat(sprintf("%d. %s (%.1f KB, %s)\n", 
              i, basename(noun_extraction_files[i]), 
              file_info$size/1024,
              format(file_info$mtime, "%Y-%m-%d %H:%M")))
}

file_choice <- get_numeric_input(
  sprintf("ë¶„ì„í•  íŒŒì¼ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-%d)", length(noun_extraction_files)),
  default = 1,
  validation_fn = function(x) {
    if (x >= 1 && x <= length(noun_extraction_files)) {
      list(valid = TRUE, value = x, message = "")
    } else {
      list(valid = FALSE, value = x, message = sprintf("1ë¶€í„° %dê¹Œì§€ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", length(noun_extraction_files)))
    }
  }
)

selected_noun_file <- noun_extraction_files[file_choice]
cat("âœ… ì„ íƒëœ ëª…ì‚¬ ì¶”ì¶œ íŒŒì¼:", basename(selected_noun_file), "\n")

# 2. ì›ë³¸ ë°ì´í„° íŒŒì¼ ì°¾ê¸°
combined_data_files <- list.files("data/processed/", 
                                 pattern = "combined_data.*\\.rds$", 
                                 full.names = TRUE)

if (length(combined_data_files) == 0) {
  stop("combined_data íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 01_data_loading_and_analysis.Rì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
}

# ê°€ì¥ ìµœì‹  ì›ë³¸ ë°ì´í„° íŒŒì¼ ìë™ ì„ íƒ
latest_combined_file <- combined_data_files[order(file.mtime(combined_data_files), decreasing = TRUE)][1]
cat("âœ… ì›ë³¸ ë©”íƒ€ë°ì´í„° íŒŒì¼:", basename(latest_combined_file), "\n\n")

# ========== ë°ì´í„° ì½ê¸° ==========
cat("ğŸ“ ë°ì´í„° ë¡œë”© ì¤‘...\n")

# ëª…ì‚¬ ì¶”ì¶œ ê²°ê³¼ ë¡œë“œ
noun_data <- read.csv(selected_noun_file, stringsAsFactors = FALSE, fileEncoding = "UTF-8")
cat(sprintf("- ëª…ì‚¬ ì¶”ì¶œ ë¬¸ì„œ ìˆ˜: %d\n", nrow(noun_data)))

# ì›ë³¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ
original_data <- readRDS(latest_combined_file)
cat(sprintf("- ì›ë³¸ ë°ì´í„° ë¬¸ì„œ ìˆ˜: %d\n", nrow(original_data)))

# ========== ë°ì´í„° ê²°í•© ë° ê²€ì¦ ==========
cat("\nğŸ”— ë°ì´í„° ê²°í•© ì¤‘...\n")

# ëª…ì‚¬ ì¶”ì¶œ ë°ì´í„°ì—ì„œ doc_id ì—´ í™•ì¸
noun_id_cols <- names(noun_data)[grepl("id|ID", names(noun_data), ignore.case = TRUE)]
if (length(noun_id_cols) == 0) {
  stop("ëª…ì‚¬ ì¶”ì¶œ ë°ì´í„°ì—ì„œ ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
}

cat("ëª…ì‚¬ ì¶”ì¶œ ë°ì´í„°ì˜ ID ì»¬ëŸ¼:\n")
for (i in seq_along(noun_id_cols)) {
  sample_vals <- head(noun_data[[noun_id_cols[i]]], 3)
  cat(sprintf("%d. %s (ì˜ˆì‹œ: %s)\n", i, noun_id_cols[i], paste(sample_vals, collapse = ", ")))
}

noun_id_choice <- get_numeric_input(
  sprintf("ëª…ì‚¬ ì¶”ì¶œ ë°ì´í„°ì˜ ë¬¸ì„œ ID ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš” (1-%d)", length(noun_id_cols)),
  default = 1,
  validation_fn = function(x) {
    if (x >= 1 && x <= length(noun_id_cols)) {
      list(valid = TRUE, value = x, message = "")
    } else {
      list(valid = FALSE, value = x, message = sprintf("1ë¶€í„° %dê¹Œì§€ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", length(noun_id_cols)))
    }
  }
)

selected_noun_id_col <- noun_id_cols[noun_id_choice]

# ì›ë³¸ ë°ì´í„°ì—ì„œ ëŒ€ì‘ë˜ëŠ” ID ì—´ í™•ì¸
original_id_cols <- names(original_data)[grepl("id|ID", names(original_data), ignore.case = TRUE)]
if (length(original_id_cols) == 0) {
  stop("ì›ë³¸ ë°ì´í„°ì—ì„œ ID ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
}

cat("\nì›ë³¸ ë°ì´í„°ì˜ ID ì»¬ëŸ¼:\n")
for (i in seq_along(original_id_cols)) {
  sample_vals <- head(original_data[[original_id_cols[i]]], 3)
  cat(sprintf("%d. %s (ì˜ˆì‹œ: %s)\n", i, original_id_cols[i], paste(sample_vals, collapse = ", ")))
}

original_id_choice <- get_numeric_input(
  sprintf("ì›ë³¸ ë°ì´í„°ì˜ ë¬¸ì„œ ID ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš” (1-%d)", length(original_id_cols)),
  default = 1,
  validation_fn = function(x) {
    if (x >= 1 && x <= length(original_id_cols)) {
      list(valid = TRUE, value = x, message = "")
    } else {
      list(valid = FALSE, value = x, message = sprintf("1ë¶€í„° %dê¹Œì§€ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", length(original_id_cols)))
    }
  }
)

selected_original_id_col <- original_id_cols[original_id_choice]

# ì„ íƒëœ ID ì»¬ëŸ¼ìœ¼ë¡œ ë°ì´í„° ê²°í•©
cat(sprintf("\nâœ… ê²°í•© ì„¤ì •: %s (ëª…ì‚¬) â†” %s (ì›ë³¸)\n", selected_noun_id_col, selected_original_id_col))

# ì„ì‹œë¡œ ì»¬ëŸ¼ëª…ì„ í†µì¼í•˜ì—¬ ë³‘í•©
noun_temp <- noun_data
original_temp <- original_data
names(noun_temp)[names(noun_temp) == selected_noun_id_col] <- "merge_id"
names(original_temp)[names(original_temp) == selected_original_id_col] <- "merge_id"

# ë°ì´í„° ê²°í•©
combined_df <- merge(noun_temp, original_temp, by = "merge_id", all.x = TRUE, suffixes = c("", "_orig"))

# ë³‘í•© í›„ doc_id ì»¬ëŸ¼ ì„¤ì • (quantedaìš©)
combined_df$doc_id <- combined_df$merge_id
cat("âœ… ë°ì´í„° ê²°í•© ì™„ë£Œ\n")

cat(sprintf("- ê²°í•©ëœ ë°ì´í„° í–‰ ìˆ˜: %d\n", nrow(combined_df)))
cat(sprintf("- ê²°í•©ëœ ë°ì´í„° ì—´ ìˆ˜: %d\n", ncol(combined_df)))

# NA ê°’ í™•ì¸
missing_nouns <- sum(is.na(combined_df$noun_extraction))
if (missing_nouns > 0) {
  cat(sprintf("âš ï¸ ëª…ì‚¬ ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ëŠ” ë¬¸ì„œ: %dê°œ\n", missing_nouns))
  combined_df <- combined_df[!is.na(combined_df$noun_extraction), ]
  cat(sprintf("âœ… ìœ íš¨í•œ ë¬¸ì„œ ìˆ˜: %dê°œ\n", nrow(combined_df)))
}

# ========== ë³µí•©ì–´ ì •ê·œí™” ==========
cat("\nğŸ”§ ë³µí•©ì–´ ì •ê·œí™” ì ìš© ì¤‘...\n")

# ë³µí•©ì–´ ë§¤í•‘ íŒŒì¼ ë¡œë“œ
compound_mappings_file <- "data/config/compound_mappings.csv"

if (file.exists(compound_mappings_file)) {
  cat(sprintf("ğŸ“„ ë³µí•©ì–´ ë§¤í•‘ íŒŒì¼ ë¡œë“œ: %s\n", compound_mappings_file))
  compound_mappings_df <- read.csv(compound_mappings_file, stringsAsFactors = FALSE, fileEncoding = "UTF-8")

  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
  mappings <- setNames(
    as.list(compound_mappings_df$replacement),
    compound_mappings_df$pattern
  )

  cat(sprintf("âœ… %dê°œì˜ ë³µí•©ì–´ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ\n", nrow(compound_mappings_df)))
} else {
  cat("âš ï¸ ë³µí•©ì–´ ë§¤í•‘ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë§¤í•‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n")
  # ê¸°ë³¸ ë§¤í•‘ (í´ë°±)
  mappings <- list(
    "ë¹„ìì‚´ì  ìí•´" = "ë¹„ìì‚´ì ìí•´",
    "ë¡œì§€ìŠ¤í‹± íšŒê·€" = "ë¡œì§€ìŠ¤í‹±íšŒê·€",
    "ë§¤ê°œ íš¨ê³¼" = "ë§¤ê°œíš¨ê³¼",
    "ì •ì„œ ì¡°ì ˆ" = "ì •ì„œì¡°ì ˆ",
    "ì •ì‹  ê±´ê°•" = "ì •ì‹ ê±´ê°•",
    "ì²­ì†Œë…„ ìí•´" = "ì²­ì†Œë…„ìí•´",
    "ìí•´ í–‰ë™" = "ìí•´í–‰ë™",
    "ì„¤ë¬¸ ì¡°ì‚¬" = "ì„¤ë¬¸ì¡°ì‚¬",
    "ì‹¤íƒœ ì¡°ì‚¬" = "ì‹¤íƒœì¡°ì‚¬"
  )
}

# ë³µí•©ì–´ ì •ê·œí™” í•¨ìˆ˜
normalize_compounds <- function(text, mappings) {
  for (pattern in names(mappings)) {
    replacement <- mappings[[pattern]]
    text <- gsub(pattern, replacement, text, fixed = TRUE)
  }
  return(text)
}

combined_df$noun_extraction_normalized <- sapply(combined_df$noun_extraction, function(x) normalize_compounds(x, mappings))

# ========== quanteda Corpus ìƒì„± ==========
cat("\nğŸ“š quanteda Corpus ìƒì„± ì¤‘...\n")

# ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼ ì‹ë³„
text_col <- "noun_extraction_normalized"
id_col <- "doc_id"

# í…ìŠ¤íŠ¸ ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
text_data <- combined_df[[text_col]]
meta_data <- combined_df[, !names(combined_df) %in% c(text_col, "noun_extraction")]

# quanteda corpus ìƒì„± (ë©”íƒ€ë°ì´í„°ë¥¼ document variablesë¡œ ì¶”ê°€)
corpus_obj <- corpus(text_data, 
                    docnames = combined_df[[id_col]])

# ë©”íƒ€ë°ì´í„°ë¥¼ document variablesë¡œ ì¶”ê°€
docvars(corpus_obj) <- meta_data

cat("âœ… Corpus ìƒì„± ì™„ë£Œ\n")
cat(sprintf("- ë¬¸ì„œ ìˆ˜: %d\n", ndoc(corpus_obj)))
cat(sprintf("- ë©”íƒ€ë°ì´í„° ë³€ìˆ˜ ìˆ˜: %d\n", ncol(meta_data)))

# ë©”íƒ€ë°ì´í„° ë³€ìˆ˜ ëª©ë¡ í‘œì‹œ
cat("\nğŸ“‹ ë³´ì¡´ëœ ë©”íƒ€ë°ì´í„° ë³€ìˆ˜:\n")
meta_vars <- names(meta_data)
for (i in seq_along(meta_vars)) {
  # ê° ë³€ìˆ˜ì˜ ìƒ˜í”Œ ê°’ í‘œì‹œ (ìµœëŒ€ 3ê°œ)
  sample_vals <- unique(meta_data[[meta_vars[i]]])[1:min(3, length(unique(meta_data[[meta_vars[i]]])))]
  sample_str <- paste(sample_vals, collapse = ", ")
  if (nchar(sample_str) > 50) {
    sample_str <- paste(substr(sample_str, 1, 47), "...")
  }
  cat(sprintf("  %2d. %-20s: %s\n", i, meta_vars[i], sample_str))
}

# ========== í† í°í™” ì„¤ì • ==========
cat("\n", rep("=", 60), "\n")
cat("âš™ï¸ í† í°í™” ì„¤ì •\n")
cat(rep("=", 60), "\n")

# í† í°í™” ë°©ì‹ ì„ íƒ
cat("\nğŸ”¤ í† í°í™” ë°©ì‹:\n")
cat("1. ì‰¼í‘œ ë¶„ë¦¬ (ê¸°ë³¸) - í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‰¼í‘œë¡œ ë¶„ë¦¬\n")
cat("2. ê³µë°± ë¶„ë¦¬ - ê³µë°±ìœ¼ë¡œ í† í°í™”\n")

tokenize_method <- get_numeric_input(
  "í† í°í™” ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš” (1-2, ê¸°ë³¸: 1)",
  default = 1,
  validation_fn = function(x) {
    if (x >= 1 && x <= 2) {
      list(valid = TRUE, value = x, message = "")
    } else {
      list(valid = FALSE, value = x, message = "1 ë˜ëŠ” 2ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    }
  }
)

# ìµœì†Œ í† í° ê¸¸ì´
min_length <- get_numeric_input(
  "ìµœì†Œ í† í° ê¸¸ì´ (1-5, ê¸°ë³¸: 2)",
  default = 2,
  validation_fn = function(x) {
    if (x >= 1 && x <= 5) {
      list(valid = TRUE, value = x, message = "")
    } else {
      list(valid = FALSE, value = x, message = "1ë¶€í„° 5ê¹Œì§€ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    }
  }
)

# ========== í† í°í™” ì‹¤í–‰ ==========
cat(sprintf("\nğŸ”¨ í† í°í™” ì‹¤í–‰ ì¤‘... (ë°©ì‹: %s, ìµœì†Œ ê¸¸ì´: %d)\n", 
            ifelse(tokenize_method == 1, "ì‰¼í‘œ ë¶„ë¦¬", "ê³µë°± ë¶„ë¦¬"), min_length))

if (tokenize_method == 1) {
  # ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ ëª…ì‚¬ë“¤ì„ ì§ì ‘ í† í°í™” (quantedaì˜ ê¸°ë³¸ ë¶„ë¦¬ ì‚¬ìš©)
  tokens_obj <- tokens(corpus_obj, 
                      what = "word",  # ê¸°ë³¸ í† í°í™”
                      remove_punct = TRUE,  # êµ¬ë‘ì  ì œê±° (ì‰¼í‘œ í¬í•¨)
                      remove_symbols = TRUE,
                      remove_numbers = FALSE) %>%
    tokens_select(min_nchar = min_length) %>%
    tokens_remove(c("", " "))  # ë¹ˆ í† í° ì œê±°
} else {
  # ì¼ë°˜ì ì¸ ê³µë°± í† í°í™”
  tokens_obj <- tokens(corpus_obj, 
                      what = "word",
                      remove_punct = TRUE,
                      remove_symbols = TRUE,
                      remove_numbers = FALSE) %>%
    tokens_select(min_nchar = min_length)
}

cat("âœ… í† í°í™” ì™„ë£Œ\n")
cat(sprintf("- í‰ê·  ë¬¸ì„œë‹¹ í† í° ìˆ˜: %.1f\n", mean(ntoken(tokens_obj))))

# ========== DFM ìƒì„± ë° í¬ì†Œì„± ê´€ë¦¬ ==========
cat("\n", rep("=", 60), "\n")
cat("ğŸ¯ DFM (Document-Feature Matrix) ìƒì„± ë° í¬ì†Œì„± ê´€ë¦¬\n")
cat(rep("=", 60), "\n")

# 1ë‹¨ê³„: ê¸°ë³¸ DFM ìƒì„± (í•„í„°ë§ ì—†ìŒ)
cat("\nğŸ“Š 1ë‹¨ê³„: ê¸°ë³¸ DFM ìƒì„± ì¤‘...\n")
dfm_original <- dfm(tokens_obj)

cat("âœ… ê¸°ë³¸ DFM ìƒì„± ì™„ë£Œ\n")
cat(sprintf("- ë¬¸ì„œ ìˆ˜: %s\n", format(ndoc(dfm_original), big.mark = ",")))
cat(sprintf("- í”¼ì²˜(ìš©ì–´) ìˆ˜: %s\n", format(nfeat(dfm_original), big.mark = ",")))
cat(sprintf("- ì´ í† í° ìˆ˜: %s\n", format(sum(dfm_original), big.mark = ",")))
# quantedaì˜ sparsity() í•¨ìˆ˜ ì‚¬ìš©
original_sparsity <- sparsity(dfm_original) * 100
cat(sprintf("- í¬ì†Œì„±: %.2f%%\n", original_sparsity))

# 2ë‹¨ê³„: í¬ì†Œì„± ê´€ë¦¬ ì„¤ì •
cat("\n", rep("=", 40), "\n")
cat("âš™ï¸ í¬ì†Œì„± ê´€ë¦¬ ì„¤ì •\n")
cat(rep("=", 40), "\n")

cat("\nğŸ“‹ í¬ì†Œì„± ê´€ë¦¬ ì˜µì…˜:\n")
cat("- ìµœì†Œ ìš©ì–´ ë¹ˆë„: ì „ì²´ ì½”í¼ìŠ¤ì—ì„œ ìš©ì–´ê°€ ë‚˜íƒ€ë‚˜ì•¼ í•  ìµœì†Œ íšŸìˆ˜\n")
cat("- ìµœì†Œ ë¬¸ì„œ ë¹ˆë„: ìš©ì–´ê°€ ë‚˜íƒ€ë‚˜ì•¼ í•  ìµœì†Œ ë¬¸ì„œ ìˆ˜\n")

# ìµœì†Œ ìš©ì–´ ë¹ˆë„ ì„¤ì •
min_termfreq <- get_numeric_input(
  sprintf("\nìµœì†Œ ìš©ì–´ ë¹ˆë„ (1-%d, ê¸°ë³¸: 2)", floor(sum(dfm_original)/1000)),
  default = 2,
  validation_fn = function(x) {
    if (x >= 1 && x <= floor(sum(dfm_original)/100)) {
      list(valid = TRUE, value = x, message = "")
    } else {
      list(valid = FALSE, value = x, message = sprintf("1ë¶€í„° %dê¹Œì§€ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", floor(sum(dfm_original)/100)))
    }
  }
)

# ìµœì†Œ ë¬¸ì„œ ë¹ˆë„ ì„¤ì •
min_docfreq <- get_numeric_input(
  sprintf("ìµœì†Œ ë¬¸ì„œ ë¹ˆë„ (1-%d, ê¸°ë³¸: 1)", floor(nrow(combined_df)/10)),
  default = 1,
  validation_fn = function(x) {
    if (x >= 1 && x <= floor(nrow(combined_df)/2)) {
      list(valid = TRUE, value = x, message = "")
    } else {
      list(valid = FALSE, value = x, message = sprintf("1ë¶€í„° %dê¹Œì§€ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", floor(nrow(combined_df)/2)))
    }
  }
)

# ìµœëŒ€ ë¬¸ì„œ ë¹ˆë„ëŠ” ì „ì²´ ë¬¸ì„œ ìˆ˜ë¡œ ì„¤ì • (ì œí•œ ì—†ìŒ)
max_docfreq <- nrow(combined_df)

cat("\nâœ… í¬ì†Œì„± ê´€ë¦¬ ì„¤ì • ì™„ë£Œ:\n")
cat(sprintf("- ìµœì†Œ ìš©ì–´ ë¹ˆë„: %díšŒ\n", min_termfreq))
cat(sprintf("- ìµœì†Œ ë¬¸ì„œ ë¹ˆë„: %dê°œ ë¬¸ì„œ\n", min_docfreq))
cat("- ìµœëŒ€ ë¬¸ì„œ ë¹ˆë„: ì œí•œ ì—†ìŒ (ëª¨ë“  ìš©ì–´ í¬í•¨)\n")

# 3ë‹¨ê³„: DFM í•„í„°ë§ ì ìš©
cat(sprintf("\nğŸ”¨ 3ë‹¨ê³„: DFM í•„í„°ë§ ì ìš© ì¤‘...\n"))
dfm_filtered <- dfm_trim(dfm_original,
                        min_termfreq = min_termfreq,
                        min_docfreq = min_docfreq, 
                        max_docfreq = max_docfreq,
                        termfreq_type = "count",
                        docfreq_type = "count")

# 4ë‹¨ê³„: í¬ì†Œì„± ë³€í™” ë¶„ì„
cat("\n", rep("=", 50), "\n")
cat("ğŸ“ˆ í¬ì†Œì„± ë³€í™” ë¶„ì„\n")
cat(rep("=", 50), "\n")

# ì›ë³¸ DFM í†µê³„
original_docs <- ndoc(dfm_original)
original_features <- nfeat(dfm_original)
original_nonzero <- sum(dfm_original > 0)  # ë¹„ì˜ê°’ ì…€ ìˆ˜
original_total_cells <- original_docs * original_features
original_sparsity_calc <- 100 * (1 - original_nonzero / original_total_cells)

# í•„í„°ë§ëœ DFM í†µê³„
filtered_docs <- ndoc(dfm_filtered)
filtered_features <- nfeat(dfm_filtered)
filtered_nonzero <- sum(dfm_filtered > 0)  # ë¹„ì˜ê°’ ì…€ ìˆ˜
filtered_total_cells <- filtered_docs * filtered_features
filtered_sparsity_calc <- 100 * (1 - filtered_nonzero / filtered_total_cells)

# ë¹„êµ ê²°ê³¼ ì¶œë ¥
cat("\nğŸ“Š DFM ë¹„êµ ê²°ê³¼:\n")
cat(sprintf("%-25s %15s %15s %15s\n", "êµ¬ë¶„", "í•„í„°ë§ ì „", "í•„í„°ë§ í›„", "ë³€í™”"))
cat(sprintf("%-25s %15s %15s %15s\n", paste(rep("-", 25), collapse=""), paste(rep("-", 15), collapse=""), paste(rep("-", 15), collapse=""), paste(rep("-", 15), collapse="")))
cat(sprintf("%-25s %15s %15s %15s\n", 
            "ë¬¸ì„œ ìˆ˜", 
            format(original_docs, big.mark = ","),
            format(filtered_docs, big.mark = ","),
            ifelse(original_docs == filtered_docs, "ë™ì¼", sprintf("%+d", filtered_docs - original_docs))))

cat(sprintf("%-25s %15s %15s %15s\n", 
            "í”¼ì²˜(ìš©ì–´) ìˆ˜", 
            format(original_features, big.mark = ","),
            format(filtered_features, big.mark = ","),
            sprintf("%+d (%.1f%%)", filtered_features - original_features,
                   100 * (filtered_features - original_features) / original_features)))

cat(sprintf("%-25s %15s %15s %15s\n", 
            "ë¹„ì˜ê°’ ì…€ ìˆ˜", 
            format(original_nonzero, big.mark = ","),
            format(filtered_nonzero, big.mark = ","),
            sprintf("%+d (%.1f%%)", filtered_nonzero - original_nonzero,
                   100 * (filtered_nonzero - original_nonzero) / original_nonzero)))

cat(sprintf("%-25s %15s %15s %15s\n", 
            "ì´ ì…€ ìˆ˜", 
            format(original_total_cells, big.mark = ","),
            format(filtered_total_cells, big.mark = ","),
            sprintf("%+d (%.1f%%)", filtered_total_cells - original_total_cells,
                   100 * (filtered_total_cells - original_total_cells) / original_total_cells)))

cat(sprintf("%-25s %15.2f%% %14.2f%% %14.2f%%p\n", 
            "í¬ì†Œì„±", 
            original_sparsity_calc,
            filtered_sparsity_calc,
            filtered_sparsity_calc - original_sparsity_calc))

# í¬ì†Œì„± ê°œì„  íš¨ê³¼ ì„¤ëª…
sparsity_improvement <- original_sparsity_calc - filtered_sparsity_calc
if (sparsity_improvement > 0) {
  cat(sprintf("\nâœ… í¬ì†Œì„± ê°œì„ : %.2f%%p ê°ì†Œ (ë” ì¡°ë°€í•œ í–‰ë ¬)\n", sparsity_improvement))
} else if (sparsity_improvement < 0) {
  cat(sprintf("\nâš ï¸ í¬ì†Œì„± ì¦ê°€: %.2f%%p ì¦ê°€ (ë” í¬ì†Œí•œ í–‰ë ¬)\n", abs(sparsity_improvement)))
} else {
  cat("\nâ¡ï¸ í¬ì†Œì„± ë³€í™” ì—†ìŒ\n")
}

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
original_memory_mb <- (original_nonzero * 8) / (1024 * 1024)  # 8ë°”ì´íŠ¸ per double
filtered_memory_mb <- (filtered_nonzero * 8) / (1024 * 1024)
memory_saved_mb <- original_memory_mb - filtered_memory_mb

cat(sprintf("\nğŸ’¾ ì¶”ì • ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:\n"))
cat(sprintf("- í•„í„°ë§ ì „: %.1f MB\n", original_memory_mb))
cat(sprintf("- í•„í„°ë§ í›„: %.1f MB\n", filtered_memory_mb))
cat(sprintf("- ì ˆì•½ëœ ë©”ëª¨ë¦¬: %.1f MB (%.1f%%)\n", 
            memory_saved_mb, 100 * memory_saved_mb / original_memory_mb))

# ìµœì¢… DFM í• ë‹¹
dfm_obj <- dfm_filtered
cat(sprintf("\nâœ… ìµœì¢… DFM ì¤€ë¹„ ì™„ë£Œ (í”¼ì²˜ ìˆ˜: %sê°œ)\n", format(nfeat(dfm_obj), big.mark = ",")))

# ========== TF-IDF ê°€ì¤‘ì¹˜ ì ìš© ì—¬ë¶€ ==========
cat("\n", rep("=", 60), "\n")
cat("âš–ï¸ TF-IDF ê°€ì¤‘ì¹˜ ì ìš©\n")
cat(rep("=", 60), "\n")

cat("\nğŸ“‹ ë¶„ì„ ì˜µì…˜:\n")
cat("1. ê¸°ë³¸ ë¹ˆë„ (Term Frequency): ë‹¨ìˆœ ì¶œí˜„ ë¹ˆë„\n")
cat("2. TF-IDF ê°€ì¤‘ì¹˜: ë¬¸ì„œë³„ ì¤‘ìš”ë„ë¥¼ ë°˜ì˜í•œ ê°€ì¤‘ì¹˜\n")
cat("   - TF-IDFëŠ” í”í•œ ìš©ì–´ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì¶”ê³  íŠ¹ì • ë¬¸ì„œì— ì§‘ì¤‘ëœ ìš©ì–´ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì„\n")

apply_tfidf <- get_yes_no_input("\nTF-IDF ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", FALSE)

if (apply_tfidf) {
  cat("\nğŸ”¨ TF-IDF ê°€ì¤‘ì¹˜ ì ìš© ì¤‘...\n")
  dfm_tfidf <- dfm_tfidf(dfm_obj)
  cat("âœ… TF-IDF ê°€ì¤‘ì¹˜ ì ìš© ì™„ë£Œ\n")
  
  # ë¶„ì„ìš© DFM ì„¤ì •
  analysis_dfm <- dfm_tfidf
  analysis_type <- "TF-IDF"
} else {
  cat("âœ… ê¸°ë³¸ ë¹ˆë„ ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n")
  analysis_dfm <- dfm_obj
  analysis_type <- "ê¸°ë³¸ ë¹ˆë„"
}

# ========== DFM ë¶„ì„ ==========
cat("\n", rep("=", 60), "\n")
cat(sprintf("ğŸ“ˆ DFM ë¶„ì„ (%s)\n", analysis_type))
cat(rep("=", 60), "\n")

# ìƒìœ„ ìš©ì–´ í‘œì‹œ ê°œìˆ˜ ì„¤ì •
top_n <- get_numeric_input(
  "\nìƒìœ„ ëª‡ ê°œ ìš©ì–´ë¥¼ í‘œì‹œí• ê¹Œìš”? (10-100, ê¸°ë³¸: 30)",
  default = 30,
  validation_fn = function(x) {
    if (x >= 10 && x <= 100) {
      list(valid = TRUE, value = x, message = "")
    } else {
      list(valid = FALSE, value = x, message = "10ë¶€í„° 100ê¹Œì§€ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    }
  }
)

# ========== 1. ê¸°ë³¸ ë¹ˆë„ ë¶„ì„ ==========
cat(sprintf("\nğŸ“Š 1. ê¸°ë³¸ ë¹ˆë„ ë¶„ì„ (ìƒìœ„ %dê°œ):\n", top_n))
cat(rep("-", 60), "\n")

# ê¸°ë³¸ ìš©ì–´ ë¹ˆë„ ê³„ì‚°
term_freq_matrix <- colSums(dfm_obj)
term_freq <- data.frame(
  feature = names(term_freq_matrix),
  frequency = as.numeric(term_freq_matrix),
  docfreq = colSums(dfm_obj > 0),  # ë¬¸ì„œ ë¹ˆë„
  stringsAsFactors = FALSE
)
term_freq <- term_freq[order(-term_freq$frequency), ]  # ë¹ˆë„ìˆœ ì •ë ¬
top_terms_freq <- head(term_freq, top_n)

for (i in 1:nrow(top_terms_freq)) {
  cat(sprintf("%3d. %-20s: %5síšŒ (ë¬¸ì„œ %dê°œ)\n", 
              i, top_terms_freq$feature[i], 
              format(top_terms_freq$frequency[i], big.mark = ","),
              top_terms_freq$docfreq[i]))
}

# ========== 2. TF-IDF ë¶„ì„ (í•­ìƒ ê³„ì‚°) ==========
cat(sprintf("\nğŸ“Š 2. TF-IDF ê°€ì¤‘ì¹˜ ë¶„ì„ (ìƒìœ„ %dê°œ):\n", top_n))
cat(rep("-", 60), "\n")

# TF-IDF í•­ìƒ ê³„ì‚° (ì‚¬ìš©ì ì„ íƒê³¼ ë¬´ê´€)
dfm_tfidf_calc <- dfm_tfidf(dfm_obj)
tfidf_scores <- colSums(dfm_tfidf_calc)
tfidf_freq <- data.frame(
  feature = names(tfidf_scores),
  tfidf_score = as.numeric(tfidf_scores),
  frequency = as.numeric(term_freq_matrix[names(tfidf_scores)]),
  docfreq = colSums(dfm_obj[, names(tfidf_scores)] > 0),
  stringsAsFactors = FALSE
)
tfidf_freq <- tfidf_freq[order(-tfidf_freq$tfidf_score), ]  # TF-IDF ì ìˆ˜ìˆœ ì •ë ¬
top_terms_tfidf <- head(tfidf_freq, top_n)

for (i in 1:nrow(top_terms_tfidf)) {
  cat(sprintf("%3d. %-20s: %6.3f (ë¹ˆë„ %síšŒ, ë¬¸ì„œ %dê°œ)\n", 
              i, top_terms_tfidf$feature[i], 
              top_terms_tfidf$tfidf_score[i],
              format(top_terms_tfidf$frequency[i], big.mark = ","),
              top_terms_tfidf$docfreq[i]))
}

# ì›Œë“œí´ë¼ìš°ë“œëŠ” ë¹ˆë„ì™€ TF-IDF ëª¨ë‘ ìƒì„±í•˜ë¯€ë¡œ viz_data ì„¤ì • ì œê±°

# ========== ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ê±´ë„ˆë›°ê¸° ==========
# ë©”íƒ€ë°ì´í„° ë¶„ì„ ì„¹ì…˜ ì œê±°

# ========== ì‹œê°í™” ==========
cat("\n", rep("=", 60), "\n")
cat("ğŸ¨ ì‹œê°í™”\n")
cat(rep("=", 60), "\n")

generate_viz <- get_yes_no_input("ì‹œê°í™”ë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", TRUE)

if (generate_viz) {
  timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
  
  # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
  wordcloud_choice <- get_yes_no_input("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", TRUE)
  
  if (wordcloud_choice) {
    max_words <- get_numeric_input(
      "ì›Œë“œí´ë¼ìš°ë“œ ìµœëŒ€ ë‹¨ì–´ ìˆ˜ (50-300, ê¸°ë³¸: 150)",
      default = 150,
      validation_fn = function(x) {
        if (x >= 50 && x <= min(300, nrow(term_freq))) {
          list(valid = TRUE, value = x, message = "")
        } else {
          list(valid = FALSE, value = x, message = sprintf("50ë¶€í„° %dê¹Œì§€ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", min(300, nrow(term_freq))))
        }
      }
    )
    
    cat("\nâ˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘...\n")
    
    # === 1. ê¸°ë³¸ ë¹ˆë„ ì›Œë“œí´ë¼ìš°ë“œ (wordcloud2) ===
    freq_wordcloud_file <- file.path("plots", sprintf("%s_quanteda_frequency_wordcloud.html", timestamp))
    
    freq_top_words <- head(term_freq, max_words)
    freq_data <- data.frame(
      word = freq_top_words$feature,
      freq = freq_top_words$frequency,
      stringsAsFactors = FALSE
    )
    
    tryCatch({
      freq_wc <- wordcloud2(freq_data, 
                           size = 0.8, 
                           color = 'random-dark',
                           backgroundColor = "white",
                           fontFamily = "ë§‘ì€ ê³ ë”•",
                           rotateRatio = 0.3)
      
      saveWidget(freq_wc, freq_wordcloud_file, selfcontained = TRUE)
      cat(sprintf("âœ… ê¸°ë³¸ ë¹ˆë„ ì›Œë“œí´ë¼ìš°ë“œ ì €ì¥: %s\n", freq_wordcloud_file))
    }, error = function(e) {
      cat(sprintf("âš ï¸ ê¸°ë³¸ ë¹ˆë„ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: %s\n", e$message))
    })
    
    # === 2. TF-IDF ì›Œë“œí´ë¼ìš°ë“œ (wordcloud2) ===
    tfidf_wordcloud_file <- file.path("plots", sprintf("%s_quanteda_tfidf_wordcloud.html", timestamp))
    
    tfidf_top_words <- head(tfidf_freq, max_words)
    
    # TF-IDF ì ìˆ˜ë¥¼ ì›Œë“œí´ë¼ìš°ë“œì— ì í•©í•œ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
    tfidf_values <- tfidf_top_words$tfidf_score
    # ìµœì†Œê°’ì´ 0 ì´í•˜ì´ë©´ ì–‘ìˆ˜ë¡œ ë³€í™˜
    if (min(tfidf_values) <= 0) {
      tfidf_values <- tfidf_values + abs(min(tfidf_values)) + 0.1
    }
    # ì ì ˆí•œ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
    tfidf_values <- round(tfidf_values * 1000)
    
    tfidf_data <- data.frame(
      word = tfidf_top_words$feature,
      freq = tfidf_values,
      stringsAsFactors = FALSE
    )
    
    tryCatch({
      tfidf_wc <- wordcloud2(tfidf_data, 
                            size = 0.8, 
                            color = 'random-light',
                            backgroundColor = "black",
                            fontFamily = "ë§‘ì€ ê³ ë”•",
                            rotateRatio = 0.3)
      
      saveWidget(tfidf_wc, tfidf_wordcloud_file, selfcontained = TRUE)
      cat(sprintf("âœ… TF-IDF ì›Œë“œí´ë¼ìš°ë“œ ì €ì¥: %s\n", tfidf_wordcloud_file))
    }, error = function(e) {
      cat(sprintf("âš ï¸ TF-IDF ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: %s\n", e$message))
    })
    
    # === 3. ë°±ì—…ìš© ê¸°ë³¸ ì›Œë“œí´ë¼ìš°ë“œ (PNG) ===
    backup_wordcloud_file <- file.path("plots", sprintf("%s_quanteda_backup_wordcloud.png", timestamp))
    
    tryCatch({
      png(filename = backup_wordcloud_file, width = 1200, height = 800, res = 100)
      set.seed(1234)
      
      wordcloud(words = freq_top_words$feature,
               freq = freq_top_words$frequency,
               min.freq = 1,
               random.order = FALSE,
               rot.per = 0.35,
               colors = brewer.pal(8, "Dark2"),
               scale = c(4, 0.5),
               family = "ë§‘ì€ ê³ ë”•")
      
      title(main = sprintf("ìƒìœ„ %dê°œ ìš©ì–´ (ê¸°ë³¸ ë¹ˆë„)", max_words), 
            cex.main = 1.5, font.main = 2)
      
      dev.off()
      cat(sprintf("âœ… ë°±ì—…ìš© PNG ì›Œë“œí´ë¼ìš°ë“œ ì €ì¥: %s\n", backup_wordcloud_file))
    }, error = function(e) {
      cat(sprintf("âš ï¸ ë°±ì—…ìš© ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: %s\n", e$message))
    })
    
  }
}

# ========== ê²°ê³¼ ì €ì¥ ==========
cat("\n", rep("=", 60), "\n")
cat("ğŸ’¾ ê²°ê³¼ ì €ì¥\n")
cat(rep("=", 60), "\n")

# íŒŒì¼ëª… ìƒì„±
dfm_filename <- sprintf("data/processed/%s_quanteda_dfm.rds", timestamp)
freq_filename <- sprintf("data/processed/%s_quanteda_frequencies.csv", timestamp)
meta_filename <- sprintf("data/processed/%s_quanteda_metadata.csv", timestamp)

# DFM ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨) - ê¸°ë³¸ ë¹ˆë„, TF-IDF, STM í˜¸í™˜ì„± ëª¨ë‘ ì €ì¥
cat("\nğŸ”„ STM í˜¸í™˜ í˜•ì‹ ë³€í™˜ ì¤‘...\n")

# STM í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
stm_conversion <- quanteda::convert(dfm_obj, to = "stm")

dfm_list <- list(
  dfm_basic = dfm_obj,
  dfm_tfidf = dfm_tfidf_calc,  # TF-IDFëŠ” í•­ìƒ ì €ì¥
  analysis_type = analysis_type,
  tfidf_applied = apply_tfidf,  # ì‚¬ìš©ì ì„ íƒ ê¸°ë¡
  
  # STM ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°
  stm_documents = stm_conversion$documents,
  stm_vocab = stm_conversion$vocab,
  stm_meta = as.data.frame(docvars(dfm_obj)),  # STMì´ ìš”êµ¬í•˜ëŠ” data.frame í˜•ì‹
  
  # STM ì—°ê³„ë¥¼ ìœ„í•œ ì¶”ê°€ ì •ë³´
  preprocessing_params = list(
    min_termfreq = min_termfreq,
    min_docfreq = min_docfreq,
    max_docfreq = max_docfreq,
    tokenize_method = tokenize_method,
    min_token_length = min_length
  ),
  corpus_info = list(
    original_docs = ndoc(dfm_original),
    filtered_docs = ndoc(dfm_obj),
    original_features = nfeat(dfm_original),
    filtered_features = nfeat(dfm_obj),
    sparsity_original = sparsity(dfm_original),
    sparsity_filtered = sparsity(dfm_obj)
  ),
  timestamp = timestamp
)

cat(sprintf("- STM ë¬¸ì„œ ìˆ˜: %d\n", length(stm_conversion$documents)))
cat(sprintf("- STM ì–´íœ˜ ìˆ˜: %d\n", length(stm_conversion$vocab)))
cat(sprintf("- STM ë©”íƒ€ë°ì´í„° ë³€ìˆ˜: %dê°œ\n", ncol(as.data.frame(docvars(dfm_obj)))))
saveRDS(dfm_list, file = dfm_filename)
cat(sprintf("âœ… DFM ì €ì¥ (STM í˜¸í™˜): %s\n", dfm_filename))

# ìš©ì–´ ë¹ˆë„ ì €ì¥ (ê¸°ë³¸ ë¹ˆë„ + TF-IDF í•­ìƒ ê²°í•©)
combined_freq <- merge(term_freq, tfidf_freq[, c("feature", "tfidf_score")], by = "feature", all.x = TRUE)
write.csv(combined_freq, file = freq_filename, row.names = FALSE, fileEncoding = "UTF-8")
cat(sprintf("âœ… ìš©ì–´ ë¹ˆë„ ì €ì¥ (ê¸°ë³¸ë¹ˆë„+TF-IDF): %s\n", freq_filename))

# ë©”íƒ€ë°ì´í„° ì €ì¥
meta_with_docnames <- cbind(docname = docnames(dfm_obj), meta_data)
write.csv(meta_with_docnames, file = meta_filename, row.names = FALSE, fileEncoding = "UTF-8")
cat(sprintf("âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: %s\n", meta_filename))

# ========== ì™„ë£Œ ë° ìš”ì•½ ==========
cat("\n", rep("=", 60), "\n")
cat("âœ… quanteda DTM ìƒì„± ì™„ë£Œ!\n")
cat(rep("=", 60), "\n")

cat("\nğŸ“‹ ìµœì¢… ìš”ì•½:\n")
cat(sprintf("- ë¶„ì„ ë°©ë²•: %s\n", analysis_type))
cat(sprintf("- ë¶„ì„ ë¬¸ì„œ ìˆ˜: %s\n", format(ndoc(dfm_obj), big.mark = ",")))
cat(sprintf("- ê³ ìœ  í”¼ì²˜ ìˆ˜: %s\n", format(nfeat(dfm_obj), big.mark = ",")))
cat(sprintf("- ì´ í† í° ìˆ˜: %s\n", format(sum(term_freq$frequency), big.mark = ",")))
cat(sprintf("- ë³´ì¡´ëœ ë©”íƒ€ë°ì´í„° ë³€ìˆ˜: %dê°œ\n", ncol(meta_data)))
cat(sprintf("- í‰ê·  ë¬¸ì„œë‹¹ í† í° ìˆ˜: %.1f\n", mean(rowSums(dfm_obj))))

cat(sprintf("- ê°€ì¥ ë¹ˆë²ˆí•œ ìš©ì–´ (ë¹ˆë„): %s (%síšŒ)\n", 
            term_freq$feature[1], format(term_freq$frequency[1], big.mark = ",")))
cat(sprintf("- ê°€ì¥ ì¤‘ìš”í•œ ìš©ì–´ (TF-IDF): %s (%.3f)\n", 
            tfidf_freq$feature[1], tfidf_freq$tfidf_score[1]))

# ë©”íƒ€ë°ì´í„° í™œìš© íŒ
if (ncol(meta_data) > 0) {
  cat("\nğŸ’¡ ë©”íƒ€ë°ì´í„° í™œìš© íŒ:\n")
  cat("- dfm_subset() í•¨ìˆ˜ë¡œ íŠ¹ì • ì¡°ê±´ì˜ ë¬¸ì„œë§Œ í•„í„°ë§ ê°€ëŠ¥\n")
  cat("- textstat_frequency() í•¨ìˆ˜ë¡œ ê·¸ë£¹ë³„ ìš©ì–´ ë¹ˆë„ ë¶„ì„ ê°€ëŠ¥\n")
  cat("- textstat_keyness() í•¨ìˆ˜ë¡œ ê·¸ë£¹ ê°„ íŠ¹ì§• ìš©ì–´ ì¶”ì¶œ ê°€ëŠ¥\n")
}